{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor,AdaBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as LGB\n",
    "from sklearn.metrics import mean_absolute_error as mae,mean_squared_log_error as rmsle,mean_squared_error as mse\n",
    "import os,re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "PATH='Restaurant prices 23.04.19/Participants_Data_Final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from mlens.ensemble import SuperLearner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chesterish',\n",
       " 'grade3',\n",
       " 'gruvboxd',\n",
       " 'gruvboxl',\n",
       " 'monokai',\n",
       " 'oceans16',\n",
       " 'onedork',\n",
       " 'solarizedd',\n",
       " 'solarizedl']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jupyterthemes as jt\n",
    "from jupyterthemes import jtplot\n",
    "jt.install_theme('chesterish')\n",
    "jtplot.style()\n",
    "jt.get_themes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "def parallel_trees(m, fn, n_jobs=8):\n",
    "        return list(ThreadPoolExecutor(n_jobs).map(fn, m.estimators_))\n",
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)\n",
    "def get_preds(t): return t.predict(valX)\n",
    "# %time preds = np.stack(parallel_trees(model, get_preds))\n",
    "# np.mean(preds[:,0]), np.std(preds[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant prices 23.04.19/Participants_Data_FinalData\n"
     ]
    }
   ],
   "source": [
    "print(f'{PATH}'+'Data')\n",
    "df_raw_1=pd.read_excel(PATH+'/Data_Train.xlsx',\n",
    "                     dtype={\n",
    "#                          'TITLE', \n",
    "                            'RESTAURANT_ID':np.int32,\n",
    "#                             'CUISINES', 'TIME', 'CITY', 'LOCALITY',\n",
    "#                             'RATING':float,\n",
    "#                             'VOTES',\n",
    "                            'COST':np.int32\n",
    "                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw=pd.read_excel(PATH+'/Data_Train.xlsx',\n",
    "                     dtype={\n",
    "#                          'TITLE', \n",
    "                            'RESTAURANT_ID':np.int32,\n",
    "#                             'CUISINES', 'TIME', 'CITY', 'LOCALITY',\n",
    "#                             'RATING':float,\n",
    "#                             'VOTES',\n",
    "                            'COST':np.int32\n",
    "                           })\n",
    "df_test=pd.read_excel(PATH+'/Data_Test.xlsx',\n",
    "                      dtype={\n",
    "#                          'TITLE', \n",
    "                            'RESTAURANT_ID':np.int32,\n",
    "#                             'CUISINES', 'TIME', 'CITY', 'LOCALITY',\n",
    "#                             'RATING':float,\n",
    "#                             'VOTES',\n",
    "                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_string_dtype\n",
    "df_temp=df_raw.copy()\n",
    "Y1=df_temp.COST\n",
    "df_temp.drop('COST',axis=1,inplace=True)\n",
    "df_temp=pd.concat([df_temp,df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TITLE', 'RESTAURANT_ID', 'CUISINES', 'TIME', 'CITY', 'LOCALITY',\n",
       "       'RATING', 'VOTES'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11am – 4pm, 7:30pm – 11:30pm (Mon-Sun)\n",
       "1                      6pm – 11pm (Mon-Sun)\n",
       "2       11am – 3:30pm, 7pm – 11pm (Mon-Sun)\n",
       "3                   11:30am – 1am (Mon-Sun)\n",
       "4                      11am – 1am (Mon-Sun)\n",
       "Name: TIME, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.TIME.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss='12midnight – 3am, 11:15am – 12midnight (Mon...'\n",
    "ss='1pm – 11pm (Mon, Tue, Thu), 1pm – 11:1pm (Wed...'\n",
    "ss.replace('midnight','am')\n",
    "ss.replace('noon','pm')\n",
    "# ss.replace('...',')') handle ...\n",
    "rad=[]\n",
    "rad.append('lays')\n",
    "rad.append('None')\n",
    "rad.pop()\n",
    "rad.append('yo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closed=[]\n",
    "# opened=[]\n",
    "# for str in df_temp.TIME:\n",
    "#     str=str.upper()\n",
    "#     str=str.replace('MIDNIGHT','AM')\n",
    "#     str=str.replace('NOON','PM')\n",
    "#     str=str.replace('...',')')\n",
    "#     str=str.replace('MON','1')\n",
    "#     str=str.replace('TUE','2')\n",
    "#     str=str.replace('WED','3')\n",
    "#     str=str.replace('THU','4')\n",
    "#     str=str.replace('FRI','5')\n",
    "#     str=str.replace('SAT','6')\n",
    "#     str=str.replace('SUN','7')\n",
    "#     time_new=''\n",
    "#     j=0\n",
    "#     closed.append('NONE')\n",
    "#     opened.append('NONE')\n",
    "#     for split_1 in str.split(','):\n",
    "#         split_1=split_1.strip()\n",
    "#         temp=re.findall(\"\\((.*?)\\)\",split_1)\n",
    "#         for item in temp:\n",
    "#             if('CLOSED' in split_1):\n",
    "#                 closed.pop()\n",
    "#                 closed.append(item) \n",
    "#             else:\n",
    "#                 opened.pop()\n",
    "#                 opened.append(item)\n",
    "#             if(j>0):time_new+=','\n",
    "#             time_new+=item\n",
    "#             j+=1\n",
    "        \n",
    "# #         split_1=re.sub(\"\\((.*?)\\)\",'',split_1)\n",
    "# #         for split_2 in split_1.split('–'):\n",
    "# #             split_2=split_2.strip()\n",
    "# #         print(split_2)\n",
    "# #     print(split_1)\n",
    "# #         if(len(temp))>0:\n",
    "# #             print((temp))\n",
    "# #             print(split_1)\n",
    "# # opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days=pd.DataFrame({'Open':opened,'Closed':closed})\n",
    "# item=days.Open.mode()\n",
    "# days.Closed.replace('NONE','0',inplace=True)\n",
    "# days.Open.replace('NONE',item[0],inplace=True)\n",
    "# # days\n",
    "# days.loc[(days.Open!=item[0])&(days.Closed=='0')]\n",
    "# # days.loc[days.Open == '[MON-SUN]']\n",
    "# # df_temp['Closed']=days.Closed\n",
    "# # df_temp['Open']=days.Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "26\n",
      "131\n",
      "434\n",
      "1588\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>RESTAURANT_ID</th>\n",
       "      <th>CUISINES</th>\n",
       "      <th>TIME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOCALITY</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VOTES</th>\n",
       "      <th>T_BAND</th>\n",
       "      <th>C_BAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>9438</td>\n",
       "      <td>MALWANI,GOAN,NORTH INDIAN</td>\n",
       "      <td>None</td>\n",
       "      <td>THANE</td>\n",
       "      <td>DOMBIVLI EAST</td>\n",
       "      <td>3.6</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASUAL DINING,BAR</td>\n",
       "      <td>13198</td>\n",
       "      <td>ASIAN,MODERN INDIAN,JAPANESE</td>\n",
       "      <td>None</td>\n",
       "      <td>CHENNAI</td>\n",
       "      <td>RAMAPURAM</td>\n",
       "      <td>4.2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>10915</td>\n",
       "      <td>NORTH INDIAN,CHINESE,BIRYANI,HYDERABADI</td>\n",
       "      <td>None</td>\n",
       "      <td>CHENNAI</td>\n",
       "      <td>SALIGRAMAM</td>\n",
       "      <td>3.8</td>\n",
       "      <td>221</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QUICK BITES</td>\n",
       "      <td>6346</td>\n",
       "      <td>TIBETAN,CHINESE</td>\n",
       "      <td>None</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>BANDRA WEST</td>\n",
       "      <td>4.1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DESSERT PARLOR</td>\n",
       "      <td>15387</td>\n",
       "      <td>DESSERTS</td>\n",
       "      <td>None</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>LOWER PAREL</td>\n",
       "      <td>3.8</td>\n",
       "      <td>165</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TITLE  RESTAURANT_ID                                 CUISINES  \\\n",
       "0      CASUAL DINING           9438                MALWANI,GOAN,NORTH INDIAN   \n",
       "1  CASUAL DINING,BAR          13198             ASIAN,MODERN INDIAN,JAPANESE   \n",
       "2      CASUAL DINING          10915  NORTH INDIAN,CHINESE,BIRYANI,HYDERABADI   \n",
       "3        QUICK BITES           6346                          TIBETAN,CHINESE   \n",
       "4     DESSERT PARLOR          15387                                 DESSERTS   \n",
       "\n",
       "   TIME     CITY       LOCALITY  RATING  VOTES  T_BAND  C_BAND  \n",
       "0  None    THANE  DOMBIVLI EAST     3.6     49       3       3  \n",
       "1  None  CHENNAI      RAMAPURAM     4.2     30       4       6  \n",
       "2  None  CHENNAI     SALIGRAMAM     3.8    221       3       2  \n",
       "3  None   MUMBAI    BANDRA WEST     4.1     24       2       1  \n",
       "4  None   MUMBAI    LOWER PAREL     3.8    165       2       0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data PreProcessing\n",
    "\n",
    "title_lc=LabelEncoder()\n",
    "cuisine_lc=LabelEncoder()\n",
    "time_lc=LabelEncoder()\n",
    "city_lc=LabelEncoder()\n",
    "locality_lc=LabelEncoder()\n",
    "\n",
    "\n",
    "# 'TIME'\n",
    "time_list=[]\n",
    "times=list(df_temp.TIME)\n",
    "for i in range (0,len(times)):\n",
    "    time=times[i]\n",
    "    time_new=''\n",
    "    j=0\n",
    "    for split_1 in time.split(','):\n",
    "        split_1=split_1.strip().upper()\n",
    "        temp=re.findall(\"\\((.*?)\\)\",split_1)\n",
    "        for item in temp:\n",
    "            if(j>0):time_new+=','\n",
    "            time_new+=item\n",
    "            j+=1\n",
    "            time_list.append(item)\n",
    "        split_1=re.sub(\"\\((.*?)\\)\",'',split_1)\n",
    "        for split_2 in split_1.split('–'):\n",
    "            split_2=split_2.strip()\n",
    "    if(len(time_new)==0):time_new='None'\n",
    "    times[i]=time_new\n",
    "df_temp.TIME=times \n",
    "time_list.append('None')\n",
    "time_list=np.unique(np.array(time_list)) \n",
    "time_lc.fit(time_list)\n",
    "print(len(time_list))\n",
    "del times\n",
    "\n",
    "#             print(split_2)\n",
    "#     print(split_1)\n",
    "#     print((temp))\n",
    "\n",
    "\n",
    "# 'TITLE'\n",
    "\n",
    "#Find title-cost connection using groupBy plot\n",
    "t_arr1=['PAAN SHOP','MESS','BHOJANALAYA','MEAT SHOP','KIOSK',\n",
    "          'IRANI CAFE','CONFECTIONERY']\n",
    "t_arr2=['FOOD COURT','BAKERY','NONE','SWEET SHOP','BEVERAGE SHOP']\n",
    "t_arr3=['None','QUICK BITES','DESSERT PARLOR','FOOD TRUCK']\n",
    "t_arr4=['CAFÉ','DHABA','CASUAL DINING']\n",
    "t_arr5=['PUB','BAR','LOUNGE','MICROBREWERY']\n",
    "t_arr6=['CLUB', 'COCKTAIL BAR',]\n",
    "t_arr7=['FINE DINING']\n",
    "\n",
    "title_list=[]\n",
    "title_band=[]\n",
    "titles=list(df_temp.TITLE)\n",
    "for i in range(0,len(titles)):\n",
    "    title=titles[i]\n",
    "    title_new=''\n",
    "    j=0\n",
    "    for item in title.split(','):\n",
    "        item=item.strip().upper()\n",
    "        title_list.append(item)\n",
    "        if(j>0):title_new+=','\n",
    "        title_new+=item\n",
    "        temp_band=0\n",
    "        if item in t_arr1:temp_band=0\n",
    "        elif item in t_arr2:temp_band=1\n",
    "        elif item in t_arr3:temp_band=2   \n",
    "        elif item in t_arr4:temp_band=3   \n",
    "        elif item in t_arr5:temp_band=4\n",
    "        elif item in t_arr6:temp_band=5\n",
    "        elif item in t_arr7:temp_band=6\n",
    "        if(len(title_band)==i):title_band.append(temp_band)\n",
    "        else:\n",
    "            if(title_band[i]<temp_band):title_band[i]=temp_band\n",
    "        \n",
    "        j+=1\n",
    "    titles[i]=title_new\n",
    "df_temp.TITLE=titles\n",
    "df_temp['T_BAND']=title_band\n",
    "title_list.append('None')\n",
    "title_list=np.unique(np.array(title_list))  \n",
    "title_lc.fit(title_list)\n",
    "print(len(title_list))\n",
    "del titles\n",
    "\n",
    "# 'CUISINES'\n",
    "\n",
    "# df_temp3=df_temp.copy()\n",
    "# df_temp3['COST']=df_raw.COST\n",
    "# col='CUISINES_1'\n",
    "# dd=df_temp3[[col,'COST']].groupby([col]).mean().sort_values(by='COST',ascending=True)\n",
    "# dd['BAND']=pd.cut(dd.COST,10)\n",
    "# dict=dd[['BAND']].groupby(['BAND']).groups\n",
    "# list_values = [ v for v in dict.values() ]\n",
    "# del df_temp3,dd\n",
    "\n",
    "#Find cuisine-cost connection using groupBy plot\n",
    "t_arr1=['PAAN', 'AFGHAN', 'TEA', 'CAFE FOOD', 'BUBBLE TEA', 'STREET FOOD',\n",
    "       'JUICES', 'CHARCOAL CHICKEN', 'ASSAMESE', 'MITHAI', 'SANDWICH',\n",
    "       'BURMESE', 'ICE CREAM', 'ORIYA', 'MOMOS', 'ROAST CHICKEN', 'FAST FOOD',\n",
    "       'WRAPS', 'BEVERAGES', 'DESSERTS', 'ROLLS', 'KEBAB', 'BAKERY',\n",
    "       'MAHARASHTRIAN', 'SOUTH INDIAN', 'COFFEE', 'BIHARI', 'BOHRI',\n",
    "       'COFFEE AND TEA' ,'FUSION','GRILL','HAWAIIAN','MISHTI' ,'MONGOLIAN','PANINI']\n",
    "t_arr2=['BIRYANI', 'KERALA', 'INDONESIAN', 'TAMIL', 'RAW MEATS', 'LUCKNOWI',\n",
    "       'MIDDLE EASTERN', 'CANTONESE', 'HOT DOGS', 'PAKISTANI', 'TIBETAN',\n",
    "       'ARABIAN', 'LEBANESE', 'PIZZA', 'BURGER', 'CHETTINAD', 'NORTH EASTERN',\n",
    "       'IRANIAN', 'TURKISH', 'HEALTHY FOOD', 'MULTI CUISINE', 'BENGALI',\n",
    "       'ANDHRA', 'SALAD', 'RAJASTHANI', 'AFRICAN', 'MUGHLAI', 'CHINESE',\n",
    "       'MANGALOREAN', 'INDIAN', 'CAFE', 'SINDHI', 'NORTH INDIAN', 'MALWANI',\n",
    "        'CUISINE VARIES','GREEK','HOT POT','JEWISH','None','VEGAN']\n",
    "t_arr3=['AWADHI', 'PARSI', 'BBQ', 'SRI LANKAN', 'NEPALESE', 'NAGA', 'GUJARATI',\n",
    "       'MEXICAN', 'ETHIOPIAN', 'SEAFOOD', 'SUSHI', 'HYDERABADI', 'GERMAN',\n",
    "       'AMERICAN','FISH AND CHIPS','SATAY']\n",
    "t_arr4=['GOAN', 'ITALIAN', 'ASIAN', 'CONTINENTAL', 'KOREAN', 'KONKAN',\n",
    "       'MALAYSIAN', 'STEAK', 'TEX-MEX', 'BRITISH', 'THAI', 'SINGAPOREAN',\n",
    "       'PORTUGUESE', 'KASHMIRI', 'RUSSIAN','DUMPLINGS','PAN ASIAN']\n",
    "t_arr5=['BAR FOOD', 'VIETNAMESE', 'FINGER FOOD', 'MODERN INDIAN','FALAFEL']\n",
    "t_arr6=['SOUTH AMERICAN', 'MEDITERRANEAN', 'FRENCH', 'EUROPEAN','BELGIAN','POKÉ']\n",
    "t_arr7=['','JAPANESE', 'DRINKS ONLY', 'ARMENIAN','MODERN AUSTRALIAN']\n",
    "# t_arr8=['SPANISH']\n",
    "# t_arr9=['IRISH','MOROCCAN']\n",
    "# t_arr10=['BRAZILIAN', 'EGYPTIAN','ORIENTAL']\n",
    "# t_arr11=['PERUVIAN']\n",
    "t_arr8=['SPANISH','IRISH','MOROCCAN','BRAZILIAN', 'EGYPTIAN','ORIENTAL','PERUVIAN']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cuisine_list=[]\n",
    "cuisine_band=[]\n",
    "cuisines=list(df_temp.CUISINES)\n",
    "for i in range(0,len(cuisines)):\n",
    "    cuisine=cuisines[i]\n",
    "    cuisine_new=''\n",
    "    j=0\n",
    "    for item in cuisine.split(','):\n",
    "        item=item.strip().upper()\n",
    "        cuisine_list.append(item)\n",
    "        if(j>0):cuisine_new+=','\n",
    "        cuisine_new+=item\n",
    "        \n",
    "        k=0\n",
    "        temp_band=0\n",
    "        if item in t_arr1:temp_band=0\n",
    "        elif item in t_arr2:temp_band=1\n",
    "        elif item in t_arr3:temp_band=2   \n",
    "        elif item in t_arr4:temp_band=3   \n",
    "        elif item in t_arr5:temp_band=4\n",
    "        elif item in t_arr6:temp_band=5\n",
    "        elif item in t_arr7:temp_band=6\n",
    "        elif item in t_arr8:temp_band=7\n",
    "#         elif item in t_arr9:temp_band=8\n",
    "#         elif item in t_arr10:temp_band=9\n",
    "#         elif item in t_arr11:temp_band=10\n",
    "        if(len(cuisine_band)==i):cuisine_band.append(temp_band)\n",
    "        else:\n",
    "            if(cuisine_band[i]<temp_band):cuisine_band[i]=temp_band\n",
    "        \n",
    "        j+=1\n",
    "    cuisines[i]=cuisine_new\n",
    "df_temp.CUISINES=cuisines\n",
    "df_temp['C_BAND']=cuisine_band\n",
    "cuisine_list.append('None')\n",
    "cuisine_list=np.unique(np.array(cuisine_list)) \n",
    "cuisine_lc.fit(cuisine_list)\n",
    "print(len(cuisine_list))\n",
    "del cuisines\n",
    "\n",
    "# 'CITY'\n",
    "cities=list(df_temp.CITY)\n",
    "for i in range(0,len(cities)):\n",
    "    city=cities[i]\n",
    "    try:\n",
    "        cities[i]=city.strip().upper()\n",
    "    except:\n",
    "        cities[i]='None'\n",
    "\n",
    "df_temp.CITY=cities\n",
    "cities=np.unique(np.array(cities))\n",
    "print(len(cities))\n",
    "# del cities\n",
    "city_lc.fit(cities)\n",
    "# 'LOCALITY'\n",
    "localities=list(df_temp.LOCALITY)\n",
    "for i in range(0,len(localities)):\n",
    "    try:\n",
    "        localities[i]=(localities[i].strip().upper())\n",
    "    except:\n",
    "        localities[i]='NONE'\n",
    "\n",
    "df_temp.LOCALITY=localities\n",
    "localities=np.unique(np.array(localities))  \n",
    "locality_lc.fit(localities)\n",
    "print(len(localities))\n",
    "# del localities\n",
    "\n",
    "# 'RATING'\n",
    "# Rating -1/0??\n",
    "df_temp.RATING.fillna(0,inplace=True)\n",
    "if 'NEW' in df_temp.RATING.values:\n",
    "    df_temp.RATING.replace('NEW',-1,inplace=True)\n",
    "if '-' in df_temp.RATING.values:\n",
    "    df_temp.RATING.replace('-',0,inplace=True)  \n",
    "if df_temp.RATING.isnull().any():    \n",
    "    df_temp.RATING.fillna(0,inplace=True)\n",
    "if is_string_dtype(df_temp.RATING):\n",
    "    df_temp.RATING=df_temp.RATING.astype('float')\n",
    "\n",
    "# 'VOTES'\n",
    "# -1/0??\n",
    "df_temp.VOTES.fillna(('-1 votes'),inplace=True)\n",
    "if not (type(df_temp.VOTES.values[0]) == np.int64 ):\n",
    "    df_temp.VOTES=df_temp.VOTES.apply(lambda x:int(x.split(' ')[0]))\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unsorted lists\n",
    "  \n",
    "if 'TITLE' in df_temp.columns.values :\n",
    "    new=df_temp.TITLE.str.split(',',expand=True)\n",
    "    for n in new:\n",
    "        if(new[n].isnull().any()):\n",
    "            new[n].fillna('None',inplace=True)\n",
    "        df_temp['TITLE_'+f'{(n+1)}']=new[n]\n",
    "    df_temp.drop('TITLE',axis=1,inplace=True)  \n",
    "\n",
    "if 'CUISINES' in df_temp.columns.values :\n",
    "    new=df_temp.CUISINES.str.split(',',expand=True)\n",
    "    for n in new:\n",
    "        if(new[n].isnull().any()):\n",
    "            new[n].fillna('None',inplace=True)\n",
    "        df_temp['CUISINES_'+f'{(n+1)}']=new[n]\n",
    "    df_temp.drop('CUISINES',axis=1,inplace=True)  \n",
    "    \n",
    "if 'TIME' in df_temp.columns.values :\n",
    "    df_temp.TIME.replace('None',df_temp.TIME.mode,inplace=True)\n",
    "    new=df_temp.TIME.str.split(',',expand=True)\n",
    "    for n in new:\n",
    "        if(new[n].isnull().any()):\n",
    "            new[n].fillna('None',inplace=True)\n",
    "        df_temp['TIME_'+f'{(n+1)}']=new[n]\n",
    "    df_temp.drop('TIME',axis=1,inplace=True)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #C_BAND\n",
    "\n",
    "\n",
    "\n",
    "# df_temp3=df_temp.copy()\n",
    "# df_temp3['COST']=df_raw.COST\n",
    "# col='CUISINES_1'\n",
    "# len(cuisine_list)\n",
    "# dd=df_temp3[[col,'COST']].groupby([col]).mean().sort_values(by='COST',ascending=True)\n",
    "# dd['BAND']=pd.cut(dd.COST,10)\n",
    "# dict=dd[['BAND']].groupby(['BAND']).groups\n",
    "# list_values = [ v for v in dict.values() ]\n",
    "# # del df_temp3,dd\n",
    "# dd[['BAND']].groupby(['BAND']).count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_temp3=df_temp.copy()\n",
    "df_temp3['COST']=df_raw.COST\n",
    "# df_temp3['Titleband']=pd.cut(df_temp3.TITLE_1,10)\n",
    "df_temp3[['T_BAND','COST']].groupby(['T_BAND']).mean().sort_values(by='COST',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "for col in df_temp.columns.values:\n",
    "    if 'TITLE' in col:\n",
    "        df_temp[col]=title_lc.transform(df_temp[col])\n",
    "    if 'CUISINE' in col:\n",
    "        df_temp[col]=cuisine_lc.transform(df_temp[col])\n",
    "    if 'TIME' in col:\n",
    "        df_temp[col]=time_lc.transform(df_temp[col])    \n",
    "    if 'CITY' in col:\n",
    "        df_temp[col]=city_lc.transform(df_temp[col])\n",
    "    if 'LOCALITY' in col:\n",
    "        df_temp[col]=locality_lc.transform(df_temp[col])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_temp.drop([\n",
    "#     'TIME',\n",
    "              'RESTAURANT_ID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOCALITY</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VOTES</th>\n",
       "      <th>T_BAND</th>\n",
       "      <th>C_BAND</th>\n",
       "      <th>TITLE_1</th>\n",
       "      <th>TITLE_2</th>\n",
       "      <th>CUISINES_1</th>\n",
       "      <th>CUISINES_2</th>\n",
       "      <th>CUISINES_3</th>\n",
       "      <th>CUISINES_4</th>\n",
       "      <th>CUISINES_5</th>\n",
       "      <th>CUISINES_6</th>\n",
       "      <th>CUISINES_7</th>\n",
       "      <th>CUISINES_8</th>\n",
       "      <th>TIME_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>397</td>\n",
       "      <td>320</td>\n",
       "      <td>3.6</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>74</td>\n",
       "      <td>47</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>1188</td>\n",
       "      <td>4.2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>82</td>\n",
       "      <td>62</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>1242</td>\n",
       "      <td>3.8</td>\n",
       "      <td>221</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>91</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271</td>\n",
       "      <td>148</td>\n",
       "      <td>4.1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>126</td>\n",
       "      <td>29</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271</td>\n",
       "      <td>688</td>\n",
       "      <td>3.8</td>\n",
       "      <td>165</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CITY  LOCALITY  RATING  VOTES  T_BAND  C_BAND  TITLE_1  TITLE_2  \\\n",
       "0   397       320     3.6     49       3       3        5       21   \n",
       "1    71      1188     4.2     30       4       6        5        1   \n",
       "2    71      1242     3.8    221       3       2        5       21   \n",
       "3   271       148     4.1     24       2       1       24       21   \n",
       "4   271       688     3.8    165       2       0        9       21   \n",
       "\n",
       "   CUISINES_1  CUISINES_2  CUISINES_3  CUISINES_4  CUISINES_5  CUISINES_6  \\\n",
       "0          74          47          91          92          92          92   \n",
       "1           7          82          62          92          92          92   \n",
       "2          91          29          17          55          92          92   \n",
       "3         126          29          92          92          92          92   \n",
       "4          34          92          92          92          92          92   \n",
       "\n",
       "   CUISINES_7  CUISINES_8  TIME_1  \n",
       "0          92          92       0  \n",
       "1          92          92       0  \n",
       "2          92          92       0  \n",
       "3          92          92       0  \n",
       "4          92          92       0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(model,check=True,file='1'):\n",
    "#     preds=sc.inverse_transform(model.predict(valX))\n",
    "#     preds=preds.astype(int)\n",
    "    \n",
    "#     \n",
    "    \n",
    "#     sc.inverse_transform\n",
    "    if check:\n",
    "        print('Score '+f'{model.score(valX,valY)}')\n",
    "        preds=model.predict(valX)\n",
    "#         print(pd.DataFrame(preds))\n",
    "#         print('rmsle '+f'{1-rmsle(preds,valY)}')\n",
    "        print('mse '+f'{sqrt(mse(preds,valY))}')\n",
    "    else:\n",
    "        preds=model.predict(df_test)\n",
    "        preds = pd.DataFrame(preds, columns = ['COST']) # Converting to dataframe\n",
    "        preds.to_excel(PATH+'/RFR'+file+'.xlsx', index = False ) # Saving the output in to an excel\n",
    "        print(preds)\n",
    "    # median prediction\n",
    "#     preds[:len(preds)]=df_raw['COST'].median()\n",
    "\n",
    "#     print('Correct: '+f'{(preds==valY).sum()}'+' Out of '+f'{len(preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7258244397174526\n",
      "0.746775149266887\n",
      "0.7795056949385477\n",
      "0.7062538181727444\n",
      "0.6967908889951588\n",
      "0.6906141879869412\n",
      "0.7514661311642197\n",
      "0.794863239486891\n"
     ]
    }
   ],
   "source": [
    "from math import log,sqrt\n",
    "# One Hot Encoding\n",
    "\n",
    "str=[]\n",
    "\n",
    "df_temp2=df_temp.copy()\n",
    "\n",
    "# drop=['CUISINES_4','CUISINES_5','CUISINES_6','CUISINES_7','CUISINES_8']\n",
    "\n",
    "# df_temp2=df_temp2.drop(str,axis=1)\n",
    "\n",
    "# df_temp2=df_temp.copy()\n",
    "\n",
    "# df_temp2.drop(['Closed'],axis=1,inplace=True)\n",
    "\n",
    "for col in df_temp2.columns.values:\n",
    "#     if 'T_BAND' in col:\n",
    "#         str.append(col)\n",
    "    if 'TITLE' in col:\n",
    "        str.append(col)\n",
    "    if 'CUISINE' in col:\n",
    "        str.append(col)\n",
    "    if 'CITY' in col:\n",
    "        str.append(col)\n",
    "    if 'LOCALITY' in col:\n",
    "        str.append(col)\n",
    "    if 'TIME' in col:\n",
    "        str.append(col) \n",
    "#     if 'Closed' in col:\n",
    "#         str.append(col)\n",
    "#     if 'Open' in col:\n",
    "#         str.append(col)\n",
    "\n",
    "df_temp2 = pd.get_dummies(df_temp2,columns=str)   # gives (1451, 221) \n",
    "#comment when run w/out FI\n",
    "\n",
    "df_temp2=df_temp2[cols]\n",
    "\n",
    "\n",
    "df_raw=df_temp2[:df_raw.shape[0]]\n",
    "\n",
    "df_test=df_temp2[df_raw.shape[0]:]\n",
    "\n",
    "df_raw['COST']=Y1\n",
    "\n",
    "df_temp2=df_raw.copy()\n",
    "\n",
    "X=df_temp2.drop([\n",
    "    'COST',\n",
    "#                  'LOCALITY','CITY'\n",
    "                ],axis=1)\n",
    "\n",
    "\n",
    "Y=df_temp2.COST\n",
    "itr=0\n",
    "while(True):\n",
    "    trainX,valX,trainY,valY=train_test_split(X,Y)\n",
    "    trainX.shape,trainY.shape,valX.shape,valY.shape\n",
    "\n",
    "# model=GradientBoostingRegressor(random_state=42,loss = 'huber',n_estimators=1000, max_depth=4,subsample=0.97,max_leaf_nodes=50,verbose=False)\n",
    "    model=LGB.LGBMRegressor(learning_rate=0.1,num_leaves=100,max_depth=6,bin=500,min_child_samples=10)    \n",
    "    model.fit(trainX,trainY)\n",
    "    score=model.score(valX,valY)\n",
    "    print(score)\n",
    "    if(score>=0.79):break\n",
    "    if(itr>=25):break\n",
    "    itr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((171, 2), (136,))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat=rf_feat_importance(model,X)\n",
    "cols=feat[feat.imp>0].cols.values\n",
    "\"\"\"\n",
    "GBR\n",
    "No Dummies 0.76,\n",
    "No FI; Dummy Title; train 0.7583,test 0.8371\n",
    "\n",
    "\"\"\"\n",
    "feat.shape,cols.shape\n",
    "# feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten,Dropout,Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import load_model,Model\n",
    "from numpy import argmax\n",
    "from os import makedirs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10152 samples, validate on 2538 samples\n",
      "Epoch 1/50\n",
      "10152/10152 [==============================] - 12s 1ms/step - loss: 332.2279 - mean_absolute_error: 332.2279 - val_loss: 233.4604 - val_mean_absolute_error: 233.4604\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 233.46036, saving model to Weights---233.46036.hdf5\n",
      "Epoch 2/50\n",
      "10152/10152 [==============================] - 5s 494us/step - loss: 230.9571 - mean_absolute_error: 230.9571 - val_loss: 210.9057 - val_mean_absolute_error: 210.9057ss: 233.9015 - mean_absolute_er\n",
      "\n",
      "Epoch 00002: val_loss improved from 233.46036 to 210.90568, saving model to Weights---210.90568.hdf5\n",
      "Epoch 3/50\n",
      "10152/10152 [==============================] - 5s 493us/step - loss: 218.1561 - mean_absolute_error: 218.1561 - val_loss: 205.1393 - val_mean_absolute_error: 205.1393\n",
      "\n",
      "Epoch 00003: val_loss improved from 210.90568 to 205.13933, saving model to Weights---205.13933.hdf5\n",
      "Epoch 4/50\n",
      "10152/10152 [==============================] - 5s 494us/step - loss: 214.5750 - mean_absolute_error: 214.5750 - val_loss: 214.9390 - val_mean_absolute_error: 214.9390\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 205.13933\n",
      "Epoch 5/50\n",
      "10152/10152 [==============================] - 5s 484us/step - loss: 206.6281 - mean_absolute_error: 206.6281 - val_loss: 194.9516 - val_mean_absolute_error: 194.9516\n",
      "\n",
      "Epoch 00005: val_loss improved from 205.13933 to 194.95157, saving model to Weights---194.95157.hdf5\n",
      "Epoch 6/50\n",
      "10152/10152 [==============================] - 5s 483us/step - loss: 201.0234 - mean_absolute_error: 201.0234 - val_loss: 183.6299 - val_mean_absolute_error: 183.6299\n",
      "\n",
      "Epoch 00006: val_loss improved from 194.95157 to 183.62990, saving model to Weights---183.62990.hdf5\n",
      "Epoch 7/50\n",
      "10152/10152 [==============================] - 5s 479us/step - loss: 194.0992 - mean_absolute_error: 194.0992 - val_loss: 192.6891 - val_mean_absolute_error: 192.6891n_absolut\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 183.62990\n",
      "Epoch 8/50\n",
      "10152/10152 [==============================] - 5s 479us/step - loss: 191.2804 - mean_absolute_error: 191.2804 - val_loss: 230.9797 - val_mean_absolute_error: 230.9797\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 183.62990\n",
      "Epoch 9/50\n",
      "10152/10152 [==============================] - 5s 482us/step - loss: 196.1001 - mean_absolute_error: 196.1001 - val_loss: 182.1879 - val_mean_absolute_error: 182.1879\n",
      "\n",
      "Epoch 00009: val_loss improved from 183.62990 to 182.18792, saving model to Weights---182.18792.hdf5\n",
      "Epoch 10/50\n",
      "10152/10152 [==============================] - 5s 476us/step - loss: 189.9915 - mean_absolute_error: 189.9915 - val_loss: 195.7759 - val_mean_absolute_error: 195.7759\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 182.18792\n",
      "Epoch 11/50\n",
      "10152/10152 [==============================] - 5s 483us/step - loss: 186.7851 - mean_absolute_error: 186.7851 - val_loss: 185.1818 - val_mean_absolute_error: 185.1818\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 182.18792\n",
      "Epoch 12/50\n",
      "10152/10152 [==============================] - 5s 479us/step - loss: 184.0013 - mean_absolute_error: 184.0013 - val_loss: 177.3468 - val_mean_absolute_error: 177.3468\n",
      "\n",
      "Epoch 00012: val_loss improved from 182.18792 to 177.34679, saving model to Weights---177.34679.hdf5\n",
      "Epoch 13/50\n",
      "10152/10152 [==============================] - 5s 469us/step - loss: 184.8149 - mean_absolute_error: 184.8149 - val_loss: 192.2877 - val_mean_absolute_error: 192.2877\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 177.34679\n",
      "Epoch 14/50\n",
      "10152/10152 [==============================] - 5s 470us/step - loss: 187.7734 - mean_absolute_error: 187.7734 - val_loss: 179.1771 - val_mean_absolute_error: 179.1771\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 177.34679\n",
      "Epoch 15/50\n",
      "10152/10152 [==============================] - 5s 467us/step - loss: 182.4650 - mean_absolute_error: 182.4650 - val_loss: 189.3441 - val_mean_absolute_error: 189.3441\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 177.34679\n",
      "Epoch 16/50\n",
      "10152/10152 [==============================] - 5s 479us/step - loss: 187.7129 - mean_absolute_error: 187.7129 - val_loss: 197.4377 - val_mean_absolute_error: 197.4377\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 177.34679\n",
      "Epoch 17/50\n",
      "10152/10152 [==============================] - 5s 468us/step - loss: 181.5127 - mean_absolute_error: 181.5127 - val_loss: 181.4910 - val_mean_absolute_error: 181.4910\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 177.34679\n",
      "Epoch 18/50\n",
      "10152/10152 [==============================] - 5s 459us/step - loss: 181.7240 - mean_absolute_error: 181.7240 - val_loss: 176.3044 - val_mean_absolute_error: 176.3044\n",
      "\n",
      "Epoch 00018: val_loss improved from 177.34679 to 176.30440, saving model to Weights---176.30440.hdf5\n",
      "Epoch 19/50\n",
      "10152/10152 [==============================] - 5s 468us/step - loss: 179.7474 - mean_absolute_error: 179.7474 - val_loss: 183.8412 - val_mean_absolute_error: 183.8412\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 176.30440\n",
      "Epoch 20/50\n",
      "10152/10152 [==============================] - 5s 453us/step - loss: 178.0805 - mean_absolute_error: 178.0805 - val_loss: 174.9445 - val_mean_absolute_error: 174.9445\n",
      "\n",
      "Epoch 00020: val_loss improved from 176.30440 to 174.94453, saving model to Weights---174.94453.hdf5\n",
      "Epoch 21/50\n",
      "10152/10152 [==============================] - 5s 466us/step - loss: 181.5630 - mean_absolute_error: 181.5630 - val_loss: 178.8707 - val_mean_absolute_error: 178.8707\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 174.94453\n",
      "Epoch 22/50\n",
      "10152/10152 [==============================] - 5s 462us/step - loss: 180.4414 - mean_absolute_error: 180.4414 - val_loss: 178.1171 - val_mean_absolute_error: 178.1171\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 174.94453\n",
      "Epoch 23/50\n",
      "10152/10152 [==============================] - 5s 454us/step - loss: 179.8914 - mean_absolute_error: 179.8914 - val_loss: 185.9491 - val_mean_absolute_error: 185.9491\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 174.94453\n",
      "Epoch 24/50\n",
      "10152/10152 [==============================] - 5s 460us/step - loss: 179.8516 - mean_absolute_error: 179.8516 - val_loss: 201.7707 - val_mean_absolute_error: 201.7707\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 174.94453\n",
      "Epoch 25/50\n",
      "10152/10152 [==============================] - 5s 454us/step - loss: 176.9428 - mean_absolute_error: 176.9428 - val_loss: 202.8354 - val_mean_absolute_error: 202.8354\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 174.94453\n",
      "Epoch 26/50\n",
      "10152/10152 [==============================] - 5s 456us/step - loss: 178.1871 - mean_absolute_error: 178.1871 - val_loss: 176.1325 - val_mean_absolute_error: 176.1325\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 174.94453\n",
      "Epoch 27/50\n",
      "10152/10152 [==============================] - 5s 453us/step - loss: 174.5606 - mean_absolute_error: 174.5606 - val_loss: 176.7714 - val_mean_absolute_error: 176.7714\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 174.94453\n",
      "Epoch 28/50\n",
      "10152/10152 [==============================] - 5s 452us/step - loss: 174.4637 - mean_absolute_error: 174.4637 - val_loss: 179.9126 - val_mean_absolute_error: 179.9126\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 174.94453\n",
      "Epoch 29/50\n",
      "10152/10152 [==============================] - 5s 446us/step - loss: 177.5379 - mean_absolute_error: 177.5379 - val_loss: 194.1045 - val_mean_absolute_error: 194.1045\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 174.94453\n",
      "Epoch 30/50\n",
      "10152/10152 [==============================] - 5s 456us/step - loss: 177.6897 - mean_absolute_error: 177.6897 - val_loss: 177.4218 - val_mean_absolute_error: 177.4218\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 174.94453\n",
      "Epoch 31/50\n",
      "10152/10152 [==============================] - 5s 454us/step - loss: 172.5954 - mean_absolute_error: 172.5954 - val_loss: 177.5716 - val_mean_absolute_error: 177.5716\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 174.94453\n",
      "Epoch 32/50\n",
      "10152/10152 [==============================] - 5s 452us/step - loss: 176.2793 - mean_absolute_error: 176.2793 - val_loss: 179.1221 - val_mean_absolute_error: 179.1221\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 174.94453\n",
      "Epoch 33/50\n",
      "10152/10152 [==============================] - 5s 453us/step - loss: 172.9620 - mean_absolute_error: 172.9620 - val_loss: 173.9503 - val_mean_absolute_error: 173.9503\n",
      "\n",
      "Epoch 00033: val_loss improved from 174.94453 to 173.95034, saving model to Weights---173.95034.hdf5\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10152/10152 [==============================] - 5s 472us/step - loss: 176.7437 - mean_absolute_error: 176.7437 - val_loss: 181.1028 - val_mean_absolute_error: 181.1028\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 173.95034\n",
      "Epoch 35/50\n",
      "10152/10152 [==============================] - 5s 474us/step - loss: 171.6435 - mean_absolute_error: 171.6435 - val_loss: 208.8851 - val_mean_absolute_error: 208.8851\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 173.95034\n",
      "Epoch 36/50\n",
      "10152/10152 [==============================] - 5s 479us/step - loss: 176.5591 - mean_absolute_error: 176.5591 - val_loss: 185.2827 - val_mean_absolute_error: 185.2827\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 173.95034\n",
      "Epoch 37/50\n",
      "10152/10152 [==============================] - 5s 468us/step - loss: 171.1774 - mean_absolute_error: 171.1774 - val_loss: 181.4238 - val_mean_absolute_error: 181.4238\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 173.95034\n",
      "Epoch 38/50\n",
      "10152/10152 [==============================] - 5s 465us/step - loss: 170.0681 - mean_absolute_error: 170.0681 - val_loss: 177.9622 - val_mean_absolute_error: 177.9622\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 173.95034\n",
      "Epoch 39/50\n",
      "10152/10152 [==============================] - 5s 467us/step - loss: 171.1200 - mean_absolute_error: 171.1200 - val_loss: 177.5964 - val_mean_absolute_error: 177.5964\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 173.95034\n",
      "Epoch 40/50\n",
      "10152/10152 [==============================] - 5s 460us/step - loss: 171.3139 - mean_absolute_error: 171.3139 - val_loss: 191.4078 - val_mean_absolute_error: 191.4078\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 173.95034\n",
      "Epoch 41/50\n",
      "10152/10152 [==============================] - 5s 459us/step - loss: 173.1779 - mean_absolute_error: 173.1779 - val_loss: 175.7165 - val_mean_absolute_error: 175.7165\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 173.95034\n",
      "Epoch 42/50\n",
      "10152/10152 [==============================] - 5s 465us/step - loss: 167.8889 - mean_absolute_error: 167.8889 - val_loss: 175.8147 - val_mean_absolute_error: 175.8147\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 173.95034\n",
      "Epoch 43/50\n",
      "10152/10152 [==============================] - 5s 457us/step - loss: 169.6063 - mean_absolute_error: 169.6063 - val_loss: 181.8862 - val_mean_absolute_error: 181.8862\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 173.95034\n",
      "Epoch 44/50\n",
      "10152/10152 [==============================] - 5s 451us/step - loss: 170.7765 - mean_absolute_error: 170.7765 - val_loss: 178.7307 - val_mean_absolute_error: 178.7307\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 173.95034\n",
      "Epoch 45/50\n",
      "10152/10152 [==============================] - 5s 461us/step - loss: 171.9134 - mean_absolute_error: 171.9134 - val_loss: 177.0343 - val_mean_absolute_error: 177.0343\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 173.95034\n",
      "Epoch 46/50\n",
      "10152/10152 [==============================] - 5s 460us/step - loss: 167.2802 - mean_absolute_error: 167.2802 - val_loss: 177.1628 - val_mean_absolute_error: 177.1628\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 173.95034\n",
      "Epoch 47/50\n",
      "10152/10152 [==============================] - 5s 446us/step - loss: 166.4043 - mean_absolute_error: 166.4043 - val_loss: 183.0076 - val_mean_absolute_error: 183.0076\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 173.95034\n",
      "Epoch 48/50\n",
      "10152/10152 [==============================] - 5s 446us/step - loss: 167.3354 - mean_absolute_error: 167.3354 - val_loss: 191.8477 - val_mean_absolute_error: 191.8477\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 173.95034\n",
      "Epoch 49/50\n",
      "10152/10152 [==============================] - 5s 445us/step - loss: 167.5215 - mean_absolute_error: 167.5215 - val_loss: 181.8594 - val_mean_absolute_error: 181.8594\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 173.95034\n",
      "Epoch 50/50\n",
      "10152/10152 [==============================] - 5s 443us/step - loss: 167.4405 - mean_absolute_error: 167.4405 - val_loss: 175.2730 - val_mean_absolute_error: 175.2730\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 173.95034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x174de6c9e48>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = X.shape[1], activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "# NN_model.add(Dropout(rate=0.8))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "# NN_model.summary()\n",
    "checkpoint_name = 'Weights---{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]\n",
    "NN_model.fit(X, Y, epochs=50, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             COST\n",
      "0      814.164124\n",
      "1      349.325378\n",
      "2      688.905273\n",
      "3      391.558868\n",
      "4      276.365356\n",
      "5      356.984619\n",
      "6      671.946045\n",
      "7      645.475647\n",
      "8      441.057983\n",
      "9      475.297241\n",
      "10     256.615875\n",
      "11     315.942627\n",
      "12    1760.119019\n",
      "13    1603.342285\n",
      "14     785.747070\n",
      "15     944.969238\n",
      "16     379.316589\n",
      "17     385.561768\n",
      "18     220.049957\n",
      "19     209.563583\n",
      "20     592.941223\n",
      "21     501.280823\n",
      "22     937.047852\n",
      "23     354.173950\n",
      "24     291.399414\n",
      "25     299.044861\n",
      "26    1117.044678\n",
      "27     558.775696\n",
      "28     431.041199\n",
      "29     398.097656\n",
      "...           ...\n",
      "4201   275.105652\n",
      "4202   332.575806\n",
      "4203   412.571777\n",
      "4204   273.909485\n",
      "4205   301.760498\n",
      "4206  3301.350830\n",
      "4207   308.287262\n",
      "4208   602.404663\n",
      "4209   623.616333\n",
      "4210   610.369812\n",
      "4211   385.733551\n",
      "4212   784.811462\n",
      "4213   563.450623\n",
      "4214   360.783752\n",
      "4215   564.270203\n",
      "4216   380.724854\n",
      "4217  2103.796143\n",
      "4218   272.057556\n",
      "4219   598.009094\n",
      "4220   501.454620\n",
      "4221   736.645569\n",
      "4222   420.858459\n",
      "4223   619.833313\n",
      "4224   344.765198\n",
      "4225   469.109955\n",
      "4226   741.753967\n",
      "4227   486.058624\n",
      "4228   408.235962\n",
      "4229   231.806198\n",
      "4230   379.672699\n",
      "\n",
      "[4231 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load wights file of the best model :\n",
    "wights_file = 'Weights---173.31224.hdf5' # choose the best checkpoint \n",
    "NN_model.load_weights(wights_file) # load it\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "# preds = NN_model.predict(X)\n",
    "# mae(preds,valY)\n",
    "print_score(NN_model,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = pd.DataFrame(yhat, columns = ['COST']) # Converting to dataframe\n",
    "# preds.to_excel(PATH+'/RFR1.xlsx', index = False ) # Saving the output in to an excel\n",
    "# print(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
