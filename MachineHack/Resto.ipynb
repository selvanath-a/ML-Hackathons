{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Score 0.8400\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor,AdaBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as LGB\n",
    "from sklearn.metrics import mean_absolute_error as mae,mean_squared_log_error as rmsle,mean_squared_error as mse\n",
    "import os,re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "PATH='Restaurant prices 23.04.19/Participants_Data_Final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import plotly.offline as py\n",
    "# py.init_notebook_mode(connected=True)\n",
    "# import plotly.graph_objs as go\n",
    "# import plotly.tools as tls\n",
    "# from mlens.ensemble import SuperLearner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jupyterthemes as jt\n",
    "# from jupyterthemes import jtplot\n",
    "# jt.install_theme('chesterish')\n",
    "# jtplot.style()\n",
    "# jt.get_themes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "def parallel_trees(m, fn, n_jobs=8):\n",
    "        return list(ThreadPoolExecutor(n_jobs).map(fn, m.estimators_))\n",
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)\n",
    "def get_preds(t): return t.predict(valX)\n",
    "# %time preds = np.stack(parallel_trees(model, get_preds))\n",
    "# np.mean(preds[:,0]), np.std(preds[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant prices 23.04.19/Participants_Data_FinalData\n"
     ]
    }
   ],
   "source": [
    "print(f'{PATH}'+'Data')\n",
    "df_raw_1=pd.read_excel(PATH+'/Data_Train.xlsx',\n",
    "                     dtype={\n",
    "#                          'TITLE', \n",
    "                            'RESTAURANT_ID':np.int32,\n",
    "#                             'CUISINES', 'TIME', 'CITY', 'LOCALITY',\n",
    "#                             'RATING':float,\n",
    "#                             'VOTES',\n",
    "                            'COST':np.int32\n",
    "                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw=pd.read_excel(PATH+'/Data_Train.xlsx',\n",
    "                     dtype={\n",
    "#                          'TITLE', \n",
    "                            'RESTAURANT_ID':np.int32,\n",
    "#                             'CUISINES', 'TIME', 'CITY', 'LOCALITY',\n",
    "#                             'RATING':float,\n",
    "#                             'VOTES',\n",
    "                            'COST':np.int32\n",
    "                           })\n",
    "df_test=pd.read_excel(PATH+'/Data_Test.xlsx',\n",
    "                      dtype={\n",
    "#                          'TITLE', \n",
    "                            'RESTAURANT_ID':np.int32,\n",
    "#                             'CUISINES', 'TIME', 'CITY', 'LOCALITY',\n",
    "#                             'RATING':float,\n",
    "#                             'VOTES',\n",
    "                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_string_dtype\n",
    "df_temp=df_raw.copy()\n",
    "Y1=df_temp.COST\n",
    "df_temp.drop('COST',axis=1,inplace=True)\n",
    "df_temp=pd.concat([df_temp,df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TITLE', 'RESTAURANT_ID', 'CUISINES', 'TIME', 'CITY', 'LOCALITY',\n",
       "       'RATING', 'VOTES'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_temp.TIME.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ss='12midnight – 3am, 11:15am – 12midnight (Mon...'\n",
    "# ss='1pm – 11pm (Mon, Tue, Thu), 1pm – 11:1pm (Wed...'\n",
    "# ss.replace('midnight','am')\n",
    "# ss.replace('noon','pm')\n",
    "# # ss.replace('...',')') handle ...\n",
    "# rad=[]\n",
    "# rad.append('lays')\n",
    "# rad.append('None')\n",
    "# rad.pop()\n",
    "# rad.append('yo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closed=[]\n",
    "# opened=[]\n",
    "# for str in df_temp.TIME:\n",
    "#     str=str.upper()\n",
    "#     str=str.replace('MIDNIGHT','AM')\n",
    "#     str=str.replace('NOON','PM')\n",
    "#     str=str.replace('...',')')\n",
    "#     str=str.replace('MON','1')\n",
    "#     str=str.replace('TUE','2')\n",
    "#     str=str.replace('WED','3')\n",
    "#     str=str.replace('THU','4')\n",
    "#     str=str.replace('FRI','5')\n",
    "#     str=str.replace('SAT','6')\n",
    "#     str=str.replace('SUN','7')\n",
    "#     time_new=''\n",
    "#     j=0\n",
    "#     closed.append('NONE')\n",
    "#     opened.append('NONE')\n",
    "#     for split_1 in str.split(','):\n",
    "#         split_1=split_1.strip()\n",
    "#         temp=re.findall(\"\\((.*?)\\)\",split_1)\n",
    "#         for item in temp:\n",
    "#             if('CLOSED' in split_1):\n",
    "#                 closed.pop()\n",
    "#                 closed.append(item) \n",
    "#             else:\n",
    "#                 opened.pop()\n",
    "#                 opened.append(item)\n",
    "#             if(j>0):time_new+=','\n",
    "#             time_new+=item\n",
    "#             j+=1\n",
    "        \n",
    "# #         split_1=re.sub(\"\\((.*?)\\)\",'',split_1)\n",
    "# #         for split_2 in split_1.split('–'):\n",
    "# #             split_2=split_2.strip()\n",
    "# #         print(split_2)\n",
    "# #     print(split_1)\n",
    "# #         if(len(temp))>0:\n",
    "# #             print((temp))\n",
    "# #             print(split_1)\n",
    "# # opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days=pd.DataFrame({'Open':opened,'Closed':closed})\n",
    "# item=days.Open.mode()\n",
    "# days.Closed.replace('NONE','0',inplace=True)\n",
    "# days.Open.replace('NONE',item[0],inplace=True)\n",
    "# # days\n",
    "# days.loc[(days.Open!=item[0])&(days.Closed=='0')]\n",
    "# # days.loc[days.Open == '[MON-SUN]']\n",
    "# # df_temp['Closed']=days.Closed\n",
    "# # df_temp['Open']=days.Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "26\n",
      "131\n",
      "434\n",
      "1588\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>RESTAURANT_ID</th>\n",
       "      <th>CUISINES</th>\n",
       "      <th>TIME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOCALITY</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VOTES</th>\n",
       "      <th>T_BAND</th>\n",
       "      <th>C_BAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>9438</td>\n",
       "      <td>MALWANI,GOAN,NORTH INDIAN</td>\n",
       "      <td>MON-SUN</td>\n",
       "      <td>THANE</td>\n",
       "      <td>DOMBIVLI EAST</td>\n",
       "      <td>3.6</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASUAL DINING,BAR</td>\n",
       "      <td>13198</td>\n",
       "      <td>ASIAN,MODERN INDIAN,JAPANESE</td>\n",
       "      <td>MON-SUN</td>\n",
       "      <td>CHENNAI</td>\n",
       "      <td>RAMAPURAM</td>\n",
       "      <td>4.2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>10915</td>\n",
       "      <td>NORTH INDIAN,CHINESE,BIRYANI,HYDERABADI</td>\n",
       "      <td>MON-SUN</td>\n",
       "      <td>CHENNAI</td>\n",
       "      <td>SALIGRAMAM</td>\n",
       "      <td>3.8</td>\n",
       "      <td>221</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QUICK BITES</td>\n",
       "      <td>6346</td>\n",
       "      <td>TIBETAN,CHINESE</td>\n",
       "      <td>MON-SUN</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>BANDRA WEST</td>\n",
       "      <td>4.1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DESSERT PARLOR</td>\n",
       "      <td>15387</td>\n",
       "      <td>DESSERTS</td>\n",
       "      <td>MON-SUN</td>\n",
       "      <td>MUMBAI</td>\n",
       "      <td>LOWER PAREL</td>\n",
       "      <td>3.8</td>\n",
       "      <td>165</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TITLE  RESTAURANT_ID                                 CUISINES  \\\n",
       "0      CASUAL DINING           9438                MALWANI,GOAN,NORTH INDIAN   \n",
       "1  CASUAL DINING,BAR          13198             ASIAN,MODERN INDIAN,JAPANESE   \n",
       "2      CASUAL DINING          10915  NORTH INDIAN,CHINESE,BIRYANI,HYDERABADI   \n",
       "3        QUICK BITES           6346                          TIBETAN,CHINESE   \n",
       "4     DESSERT PARLOR          15387                                 DESSERTS   \n",
       "\n",
       "      TIME     CITY       LOCALITY  RATING  VOTES  T_BAND  C_BAND  \n",
       "0  MON-SUN    THANE  DOMBIVLI EAST     3.6     49       3       3  \n",
       "1  MON-SUN  CHENNAI      RAMAPURAM     4.2     30       4       6  \n",
       "2  MON-SUN  CHENNAI     SALIGRAMAM     3.8    221       3       2  \n",
       "3  MON-SUN   MUMBAI    BANDRA WEST     4.1     24       2       1  \n",
       "4  MON-SUN   MUMBAI    LOWER PAREL     3.8    165       2       0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data PreProcessing\n",
    "\n",
    "title_lc=LabelEncoder()\n",
    "cuisine_lc=LabelEncoder()\n",
    "time_lc=LabelEncoder()\n",
    "city_lc=LabelEncoder()\n",
    "locality_lc=LabelEncoder()\n",
    "\n",
    "\n",
    "# 'TIME'\n",
    "time_list=[]\n",
    "times=list(df_temp.TIME)\n",
    "for i in range (0,len(times)):\n",
    "    time=times[i]\n",
    "    time_new=''\n",
    "    j=0\n",
    "    for split_1 in time.split(','):\n",
    "        split_1=split_1.strip().upper()\n",
    "        temp=re.findall(\"\\((.*?)\\)\",split_1)\n",
    "        for item in temp:\n",
    "            if(j>0):time_new+=','\n",
    "            time_new+=item\n",
    "            j+=1\n",
    "            time_list.append(item)\n",
    "        split_1=re.sub(\"\\((.*?)\\)\",'',split_1)\n",
    "        for split_2 in split_1.split('–'):\n",
    "            split_2=split_2.strip()\n",
    "    if(len(time_new)==0):time_new='None'\n",
    "    times[i]=time_new\n",
    "df_temp.TIME=times \n",
    "time_list.append('None')\n",
    "time_list=np.unique(np.array(time_list)) \n",
    "time_lc.fit(time_list)\n",
    "print(len(time_list))\n",
    "del times\n",
    "\n",
    "#             print(split_2)\n",
    "#     print(split_1)\n",
    "#     print((temp))\n",
    "\n",
    "\n",
    "# 'TITLE'\n",
    "\n",
    "#Find title-cost connection using groupBy plot\n",
    "t_arr1=['PAAN SHOP','MESS','BHOJANALAYA','MEAT SHOP','KIOSK',\n",
    "          'IRANI CAFE','CONFECTIONERY']\n",
    "t_arr2=['FOOD COURT','BAKERY','NONE','SWEET SHOP','BEVERAGE SHOP']\n",
    "t_arr3=['None','QUICK BITES','DESSERT PARLOR','FOOD TRUCK']\n",
    "t_arr4=['CAFÉ','DHABA','CASUAL DINING']\n",
    "t_arr5=['PUB','BAR','LOUNGE','MICROBREWERY']\n",
    "t_arr6=['CLUB', 'COCKTAIL BAR',]\n",
    "t_arr7=['FINE DINING']\n",
    "\n",
    "title_list=[]\n",
    "title_band=[]\n",
    "titles=list(df_temp.TITLE)\n",
    "for i in range(0,len(titles)):\n",
    "    title=titles[i]\n",
    "    title_new=''\n",
    "    j=0\n",
    "    for item in title.split(','):\n",
    "        item=item.strip().upper()\n",
    "        title_list.append(item)\n",
    "        if(j>0):title_new+=','\n",
    "        title_new+=item\n",
    "        temp_band=0\n",
    "        if item in t_arr1:temp_band=0\n",
    "        elif item in t_arr2:temp_band=1\n",
    "        elif item in t_arr3:temp_band=2   \n",
    "        elif item in t_arr4:temp_band=3   \n",
    "        elif item in t_arr5:temp_band=4\n",
    "        elif item in t_arr6:temp_band=5\n",
    "        elif item in t_arr7:temp_band=6\n",
    "        if(len(title_band)==i):title_band.append(temp_band)\n",
    "        else:\n",
    "            if(title_band[i]<temp_band):title_band[i]=temp_band\n",
    "        \n",
    "        j+=1\n",
    "    titles[i]=title_new\n",
    "df_temp.TITLE=titles\n",
    "df_temp['T_BAND']=title_band\n",
    "title_list.append('None')\n",
    "title_list=np.unique(np.array(title_list))  \n",
    "title_lc.fit(title_list)\n",
    "print(len(title_list))\n",
    "del titles\n",
    "\n",
    "# 'CUISINES'\n",
    "\n",
    "# df_temp3=df_temp.copy()\n",
    "# df_temp3['COST']=df_raw.COST\n",
    "# col='CUISINES_1'\n",
    "# dd=df_temp3[[col,'COST']].groupby([col]).mean().sort_values(by='COST',ascending=True)\n",
    "# dd['BAND']=pd.cut(dd.COST,10)\n",
    "# dict=dd[['BAND']].groupby(['BAND']).groups\n",
    "# list_values = [ v for v in dict.values() ]\n",
    "# del df_temp3,dd\n",
    "\n",
    "#Find cuisine-cost connection using groupBy plot\n",
    "t_arr1=['PAAN', 'AFGHAN', 'TEA', 'CAFE FOOD', 'BUBBLE TEA', 'STREET FOOD',\n",
    "       'JUICES', 'CHARCOAL CHICKEN', 'ASSAMESE', 'MITHAI', 'SANDWICH',\n",
    "       'BURMESE', 'ICE CREAM', 'ORIYA', 'MOMOS', 'ROAST CHICKEN', 'FAST FOOD',\n",
    "       'WRAPS', 'BEVERAGES', 'DESSERTS', 'ROLLS', 'KEBAB', 'BAKERY',\n",
    "       'MAHARASHTRIAN', 'SOUTH INDIAN', 'COFFEE', 'BIHARI', 'BOHRI',\n",
    "       'COFFEE AND TEA' ,'FUSION','GRILL','HAWAIIAN','MISHTI' ,'MONGOLIAN','PANINI']\n",
    "t_arr2=['BIRYANI', 'KERALA', 'INDONESIAN', 'TAMIL', 'RAW MEATS', 'LUCKNOWI',\n",
    "       'MIDDLE EASTERN', 'CANTONESE', 'HOT DOGS', 'PAKISTANI', 'TIBETAN',\n",
    "       'ARABIAN', 'LEBANESE', 'PIZZA', 'BURGER', 'CHETTINAD', 'NORTH EASTERN',\n",
    "       'IRANIAN', 'TURKISH', 'HEALTHY FOOD', 'MULTI CUISINE', 'BENGALI',\n",
    "       'ANDHRA', 'SALAD', 'RAJASTHANI', 'AFRICAN', 'MUGHLAI', 'CHINESE',\n",
    "       'MANGALOREAN', 'INDIAN', 'CAFE', 'SINDHI', 'NORTH INDIAN', 'MALWANI',\n",
    "        'CUISINE VARIES','GREEK','HOT POT','JEWISH','None','VEGAN']\n",
    "t_arr3=['AWADHI', 'PARSI', 'BBQ', 'SRI LANKAN', 'NEPALESE', 'NAGA', 'GUJARATI',\n",
    "       'MEXICAN', 'ETHIOPIAN', 'SEAFOOD', 'SUSHI', 'HYDERABADI', 'GERMAN',\n",
    "       'AMERICAN','FISH AND CHIPS','SATAY']\n",
    "t_arr4=['GOAN', 'ITALIAN', 'ASIAN', 'CONTINENTAL', 'KOREAN', 'KONKAN',\n",
    "       'MALAYSIAN', 'STEAK', 'TEX-MEX', 'BRITISH', 'THAI', 'SINGAPOREAN',\n",
    "       'PORTUGUESE', 'KASHMIRI', 'RUSSIAN','DUMPLINGS','PAN ASIAN']\n",
    "t_arr5=['BAR FOOD', 'VIETNAMESE', 'FINGER FOOD', 'MODERN INDIAN','FALAFEL']\n",
    "t_arr6=['SOUTH AMERICAN', 'MEDITERRANEAN', 'FRENCH', 'EUROPEAN','BELGIAN','POKÉ']\n",
    "t_arr7=['','JAPANESE', 'DRINKS ONLY', 'ARMENIAN','MODERN AUSTRALIAN']\n",
    "# t_arr8=['SPANISH']\n",
    "# t_arr9=['IRISH','MOROCCAN']\n",
    "# t_arr10=['BRAZILIAN', 'EGYPTIAN','ORIENTAL']\n",
    "# t_arr11=['PERUVIAN']\n",
    "t_arr8=['SPANISH','IRISH','MOROCCAN','BRAZILIAN', 'EGYPTIAN','ORIENTAL','PERUVIAN']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cuisine_list=[]\n",
    "cuisine_band=[]\n",
    "cuisines=list(df_temp.CUISINES)\n",
    "for i in range(0,len(cuisines)):\n",
    "    cuisine=cuisines[i]\n",
    "    cuisine_new=''\n",
    "    j=0\n",
    "    for item in cuisine.split(','):\n",
    "        item=item.strip().upper()\n",
    "        cuisine_list.append(item)\n",
    "        if(j>0):cuisine_new+=','\n",
    "        cuisine_new+=item\n",
    "        \n",
    "        k=0\n",
    "        temp_band=0\n",
    "        if item in t_arr1:temp_band=0\n",
    "        elif item in t_arr2:temp_band=1\n",
    "        elif item in t_arr3:temp_band=2   \n",
    "        elif item in t_arr4:temp_band=3   \n",
    "        elif item in t_arr5:temp_band=4\n",
    "        elif item in t_arr6:temp_band=5\n",
    "        elif item in t_arr7:temp_band=6\n",
    "        elif item in t_arr8:temp_band=7\n",
    "#         elif item in t_arr9:temp_band=8\n",
    "#         elif item in t_arr10:temp_band=9\n",
    "#         elif item in t_arr11:temp_band=10\n",
    "        if(len(cuisine_band)==i):cuisine_band.append(temp_band)\n",
    "        else:\n",
    "            if(cuisine_band[i]<temp_band):cuisine_band[i]=temp_band\n",
    "        \n",
    "        j+=1\n",
    "    cuisines[i]=cuisine_new\n",
    "df_temp.CUISINES=cuisines\n",
    "df_temp['C_BAND']=cuisine_band\n",
    "cuisine_list.append('None')\n",
    "cuisine_list=np.unique(np.array(cuisine_list)) \n",
    "cuisine_lc.fit(cuisine_list)\n",
    "print(len(cuisine_list))\n",
    "del cuisines\n",
    "\n",
    "# 'CITY'\n",
    "cities=list(df_temp.CITY)\n",
    "for i in range(0,len(cities)):\n",
    "    city=cities[i]\n",
    "    try:\n",
    "        cities[i]=city.strip().upper()\n",
    "    except:\n",
    "        cities[i]='None'\n",
    "\n",
    "df_temp.CITY=cities\n",
    "cities=np.unique(np.array(cities))\n",
    "print(len(cities))\n",
    "# del cities\n",
    "city_lc.fit(cities)\n",
    "# 'LOCALITY'\n",
    "localities=list(df_temp.LOCALITY)\n",
    "for i in range(0,len(localities)):\n",
    "    try:\n",
    "        localities[i]=(localities[i].strip().upper())\n",
    "    except:\n",
    "        localities[i]='NONE'\n",
    "\n",
    "df_temp.LOCALITY=localities\n",
    "localities=np.unique(np.array(localities))  \n",
    "locality_lc.fit(localities)\n",
    "print(len(localities))\n",
    "# del localities\n",
    "\n",
    "# 'RATING'\n",
    "# Rating -1/0??\n",
    "df_temp.RATING.fillna(0,inplace=True)\n",
    "if 'NEW' in df_temp.RATING.values:\n",
    "    df_temp.RATING.replace('NEW',-1,inplace=True)\n",
    "if '-' in df_temp.RATING.values:\n",
    "    df_temp.RATING.replace('-',0,inplace=True)  \n",
    "if df_temp.RATING.isnull().any():    \n",
    "    df_temp.RATING.fillna(0,inplace=True)\n",
    "if is_string_dtype(df_temp.RATING):\n",
    "    df_temp.RATING=df_temp.RATING.astype('float')\n",
    "\n",
    "# 'VOTES'\n",
    "# -1/0??\n",
    "df_temp.VOTES.fillna(('-1 votes'),inplace=True)\n",
    "if not (type(df_temp.VOTES.values[0]) == np.int64 ):\n",
    "    df_temp.VOTES=df_temp.VOTES.apply(lambda x:int(x.split(' ')[0]))\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unsorted lists\n",
    "  \n",
    "if 'TITLE' in df_temp.columns.values :\n",
    "    new=df_temp.TITLE.str.split(',',expand=True)\n",
    "    for n in new:\n",
    "        if(new[n].isnull().any()):\n",
    "            new[n].fillna('None',inplace=True)\n",
    "        df_temp['TITLE_'+f'{(n+1)}']=new[n]\n",
    "    df_temp.drop('TITLE',axis=1,inplace=True)  \n",
    "\n",
    "if 'CUISINES' in df_temp.columns.values :\n",
    "    new=df_temp.CUISINES.str.split(',',expand=True)\n",
    "    for n in new:\n",
    "        if(new[n].isnull().any()):\n",
    "            new[n].fillna('None',inplace=True)\n",
    "        df_temp['CUISINES_'+f'{(n+1)}']=new[n]\n",
    "    df_temp.drop('CUISINES',axis=1,inplace=True)  \n",
    "    \n",
    "if 'TIME' in df_temp.columns.values :\n",
    "    df_temp.TIME.replace('None',df_temp.TIME.mode,inplace=True)\n",
    "    new=df_temp.TIME.str.split(',',expand=True)\n",
    "    for n in new:\n",
    "        if(new[n].isnull().any()):\n",
    "            new[n].fillna('None',inplace=True)\n",
    "        df_temp['TIME_'+f'{(n+1)}']=new[n]\n",
    "    df_temp.drop('TIME',axis=1,inplace=True)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(187.19, 471.0]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(471.0, 752.0]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(752.0, 1033.0]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1033.0, 1314.0]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1314.0, 1595.0]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1595.0, 1876.0]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1876.0, 2157.0]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2157.0, 2438.0]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2438.0, 2719.0]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2719.0, 3000.0]</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(187.19, 471.0], (471.0, 752.0], (752.0, 1033.0], (1033.0, 1314.0], (1314.0, 1595.0], (1595.0, 1876.0], (1876.0, 2157.0], (2157.0, 2438.0], (2438.0, 2719.0], (2719.0, 3000.0]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #C_BAND\n",
    "\n",
    "\n",
    "\n",
    "df_temp3=df_temp.copy()\n",
    "df_temp3['COST']=df_raw.COST\n",
    "col='CUISINES_1'\n",
    "len(cuisine_list)\n",
    "dd=df_temp3[[col,'COST']].groupby([col]).mean().sort_values(by='COST',ascending=True)\n",
    "dd['BAND']=pd.cut(dd.COST,10)\n",
    "dict=dd[['BAND']].groupby(['BAND']).groups\n",
    "list_values = [ v for v in dict.values() ]\n",
    "# del df_temp3,dd\n",
    "dd[['BAND']].groupby(['BAND']).count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COST</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_BAND</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307.814570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>422.777598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>446.699760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>720.892419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1286.483594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1882.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2374.401709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               COST\n",
       "T_BAND             \n",
       "0        307.814570\n",
       "2        422.777598\n",
       "1        446.699760\n",
       "3        720.892419\n",
       "4       1286.483594\n",
       "5       1882.222222\n",
       "6       2374.401709"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp3=df_temp.copy()\n",
    "df_temp3['COST']=df_raw.COST\n",
    "# df_temp3['Titleband']=pd.cut(df_temp3.TITLE_1,10)\n",
    "df_temp3[['T_BAND','COST']].groupby(['T_BAND']).mean().sort_values(by='COST',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "for col in df_temp.columns.values:\n",
    "    if 'TITLE' in col:\n",
    "        df_temp[col]=title_lc.transform(df_temp[col])\n",
    "    if 'CUISINE' in col:\n",
    "        df_temp[col]=cuisine_lc.transform(df_temp[col])\n",
    "    if 'TIME' in col:\n",
    "        df_temp[col]=time_lc.transform(df_temp[col])    \n",
    "    if 'CITY' in col:\n",
    "        df_temp[col]=city_lc.transform(df_temp[col])\n",
    "    if 'LOCALITY' in col:\n",
    "        df_temp[col]=locality_lc.transform(df_temp[col])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_temp.drop([\n",
    "#     'TIME',\n",
    "              'RESTAURANT_ID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOCALITY</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VOTES</th>\n",
       "      <th>T_BAND</th>\n",
       "      <th>C_BAND</th>\n",
       "      <th>TITLE_1</th>\n",
       "      <th>TITLE_2</th>\n",
       "      <th>CUISINES_1</th>\n",
       "      <th>CUISINES_2</th>\n",
       "      <th>CUISINES_3</th>\n",
       "      <th>CUISINES_4</th>\n",
       "      <th>CUISINES_5</th>\n",
       "      <th>CUISINES_6</th>\n",
       "      <th>CUISINES_7</th>\n",
       "      <th>CUISINES_8</th>\n",
       "      <th>TIME_1</th>\n",
       "      <th>TIME_2</th>\n",
       "      <th>TIME_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>397</td>\n",
       "      <td>320</td>\n",
       "      <td>3.6</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>74</td>\n",
       "      <td>47</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>1188</td>\n",
       "      <td>4.2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>82</td>\n",
       "      <td>62</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>1242</td>\n",
       "      <td>3.8</td>\n",
       "      <td>221</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>91</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271</td>\n",
       "      <td>148</td>\n",
       "      <td>4.1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>126</td>\n",
       "      <td>29</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271</td>\n",
       "      <td>688</td>\n",
       "      <td>3.8</td>\n",
       "      <td>165</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CITY  LOCALITY  RATING  VOTES  T_BAND  C_BAND  TITLE_1  TITLE_2  \\\n",
       "0   397       320     3.6     49       3       3        5       21   \n",
       "1    71      1188     4.2     30       4       6        5        1   \n",
       "2    71      1242     3.8    221       3       2        5       21   \n",
       "3   271       148     4.1     24       2       1       24       21   \n",
       "4   271       688     3.8    165       2       0        9       21   \n",
       "\n",
       "   CUISINES_1  CUISINES_2  CUISINES_3  CUISINES_4  CUISINES_5  CUISINES_6  \\\n",
       "0          74          47          91          92          92          92   \n",
       "1           7          82          62          92          92          92   \n",
       "2          91          29          17          55          92          92   \n",
       "3         126          29          92          92          92          92   \n",
       "4          34          92          92          92          92          92   \n",
       "\n",
       "   CUISINES_7  CUISINES_8  TIME_1  TIME_2  TIME_3  \n",
       "0          92          92       6      10      10  \n",
       "1          92          92       6      10      10  \n",
       "2          92          92       6      10      10  \n",
       "3          92          92       6      10      10  \n",
       "4          92          92       6      10      10  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(model,check=True,file='1'):\n",
    "#     preds=sc.inverse_transform(model.predict(valX))\n",
    "#     preds=preds.astype(int)\n",
    "    \n",
    "#     \n",
    "    \n",
    "#     sc.inverse_transform\n",
    "    if check:\n",
    "        print('Score '+f'{model.score(valX,valY)}')\n",
    "        preds=model.predict(valX)\n",
    "#         print(pd.DataFrame(preds))\n",
    "#         print('rmsle '+f'{1-rmsle(preds,valY)}')\n",
    "        print('mse '+f'{sqrt(mse(preds,valY))}')\n",
    "    else:\n",
    "        preds=model.predict(df_test)\n",
    "        preds = pd.DataFrame(preds, columns = ['COST']) # Converting to dataframe\n",
    "        preds.to_excel(PATH+'/RFR'+file+'.xlsx', index = False ) # Saving the output in to an excel\n",
    "        print(preds)\n",
    "    # median prediction\n",
    "#     preds[:len(preds)]=df_raw['COST'].median()\n",
    "\n",
    "#     print('Correct: '+f'{(preds==valY).sum()}'+' Out of '+f'{len(preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748227624717558\n",
      "0.7751975787609674\n",
      "0.7707036058358923\n",
      "0.7942026262692272\n"
     ]
    }
   ],
   "source": [
    "from math import log,sqrt\n",
    "# One Hot Encoding\n",
    "\n",
    "str=[]\n",
    "\n",
    "df_temp2=df_temp.copy()\n",
    "\n",
    "# drop=['CUISINES_4','CUISINES_5','CUISINES_6','CUISINES_7','CUISINES_8']\n",
    "\n",
    "# df_temp2=df_temp2.drop(str,axis=1)\n",
    "\n",
    "# df_temp2=df_temp.copy()\n",
    "\n",
    "# df_temp2.drop(['Closed'],axis=1,inplace=True)\n",
    "\n",
    "for col in df_temp2.columns.values:\n",
    "#     if 'T_BAND' in col:\n",
    "#         str.append(col)\n",
    "    if 'TITLE' in col:\n",
    "        str.append(col)\n",
    "    if 'CUISINE' in col:\n",
    "        str.append(col)\n",
    "    if 'CITY' in col:\n",
    "        str.append(col)\n",
    "    if 'LOCALITY' in col:\n",
    "        str.append(col)\n",
    "    if 'TIME' in col:\n",
    "        str.append(col) \n",
    "#     if 'Closed' in col:\n",
    "#         str.append(col)\n",
    "#     if 'Open' in col:\n",
    "#         str.append(col)\n",
    "\n",
    "df_temp2 = pd.get_dummies(df_temp2,columns=str)   # gives (1451, 221) \n",
    "#comment when run w/out FI\n",
    "\n",
    "#post FI\n",
    "df_temp2=df_temp2[cols]\n",
    "\n",
    "\n",
    "df_raw=df_temp2[:df_raw.shape[0]]\n",
    "\n",
    "df_test=df_temp2[df_raw.shape[0]:]\n",
    "\n",
    "df_raw['COST']=Y1\n",
    "\n",
    "df_temp2=df_raw.copy()\n",
    "\n",
    "X=df_temp2.drop([\n",
    "    'COST',\n",
    "#                  'LOCALITY','CITY'\n",
    "                ],axis=1)\n",
    "\n",
    "\n",
    "Y=df_temp2.COST\n",
    "itr=0\n",
    "while(True):\n",
    "    trainX,valX,trainY,valY=train_test_split(X,Y)\n",
    "    trainX.shape,trainY.shape,valX.shape,valY.shape\n",
    "\n",
    "# model=GradientBoostingRegressor(random_state=42,loss = 'huber',n_estimators=1000, max_depth=4,subsample=0.97,max_leaf_nodes=50,verbose=False)\n",
    "    model=LGB.LGBMRegressor(learning_rate=0.1,num_leaves=100,max_depth=6,bin=500,min_child_samples=10)    \n",
    "    model.fit(trainX,trainY)\n",
    "    score=model.score(valX,valY)\n",
    "    print(score)\n",
    "    if(score>=0.79):break\n",
    "    if(itr>=25):break\n",
    "    itr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2745, 2), (170,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat=rf_feat_importance(model,X)\n",
    "cols=feat[feat.imp>0].cols.values\n",
    "\"\"\"\n",
    "GBR\n",
    "No Dummies 0.76,\n",
    "No FI; Dummy Title; train 0.7583,test 0.8371\n",
    "\n",
    "\"\"\"\n",
    "feat.shape,cols.shape\n",
    "# feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten,Dropout,Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import load_model,Model\n",
    "from numpy import argmax\n",
    "from os import makedirs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From H:\\Software\\Conda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From H:\\Software\\Conda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 10152 samples, validate on 2538 samples\n",
      "Epoch 1/50\n",
      "10152/10152 [==============================] - 2s 185us/step - loss: 328.3109 - mean_absolute_error: 328.3109 - val_loss: 287.3558 - val_mean_absolute_error: 287.3558\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 287.35582, saving model to Weights---287.35582.hdf5\n",
      "Epoch 2/50\n",
      "10152/10152 [==============================] - 2s 158us/step - loss: 237.9924 - mean_absolute_error: 237.9924 - val_loss: 217.7914 - val_mean_absolute_error: 217.7914\n",
      "\n",
      "Epoch 00002: val_loss improved from 287.35582 to 217.79137, saving model to Weights---217.79137.hdf5\n",
      "Epoch 3/50\n",
      "10152/10152 [==============================] - 2s 150us/step - loss: 218.0536 - mean_absolute_error: 218.0536 - val_loss: 210.7547 - val_mean_absolute_error: 210.7547\n",
      "\n",
      "Epoch 00003: val_loss improved from 217.79137 to 210.75473, saving model to Weights---210.75473.hdf5\n",
      "Epoch 4/50\n",
      "10152/10152 [==============================] - 1s 142us/step - loss: 217.1621 - mean_absolute_error: 217.1621 - val_loss: 204.0290 - val_mean_absolute_error: 204.0290\n",
      "\n",
      "Epoch 00004: val_loss improved from 210.75473 to 204.02897, saving model to Weights---204.02897.hdf5\n",
      "Epoch 5/50\n",
      "10152/10152 [==============================] - 1s 147us/step - loss: 204.8952 - mean_absolute_error: 204.8952 - val_loss: 206.0767 - val_mean_absolute_error: 206.0767\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 204.02897\n",
      "Epoch 6/50\n",
      "10152/10152 [==============================] - 2s 152us/step - loss: 197.0489 - mean_absolute_error: 197.0489 - val_loss: 184.9142 - val_mean_absolute_error: 184.9142\n",
      "\n",
      "Epoch 00006: val_loss improved from 204.02897 to 184.91421, saving model to Weights---184.91421.hdf5\n",
      "Epoch 7/50\n",
      "10152/10152 [==============================] - 2s 149us/step - loss: 191.1068 - mean_absolute_error: 191.1068 - val_loss: 177.4937 - val_mean_absolute_error: 177.4937\n",
      "\n",
      "Epoch 00007: val_loss improved from 184.91421 to 177.49371, saving model to Weights---177.49371.hdf5\n",
      "Epoch 8/50\n",
      "10152/10152 [==============================] - 1s 139us/step - loss: 194.1721 - mean_absolute_error: 194.1721 - val_loss: 176.9946 - val_mean_absolute_error: 176.9946\n",
      "\n",
      "Epoch 00008: val_loss improved from 177.49371 to 176.99460, saving model to Weights---176.99460.hdf5\n",
      "Epoch 9/50\n",
      "10152/10152 [==============================] - 2s 152us/step - loss: 190.2234 - mean_absolute_error: 190.2234 - val_loss: 181.9343 - val_mean_absolute_error: 181.9343\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 176.99460\n",
      "Epoch 10/50\n",
      "10152/10152 [==============================] - 2s 195us/step - loss: 185.6249 - mean_absolute_error: 185.6249 - val_loss: 179.2286 - val_mean_absolute_error: 179.2286\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 176.99460\n",
      "Epoch 11/50\n",
      "10152/10152 [==============================] - 2s 172us/step - loss: 186.3126 - mean_absolute_error: 186.3126 - val_loss: 192.8386 - val_mean_absolute_error: 192.8386\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 176.99460\n",
      "Epoch 12/50\n",
      "10152/10152 [==============================] - 1s 148us/step - loss: 184.9706 - mean_absolute_error: 184.9706 - val_loss: 181.5635 - val_mean_absolute_error: 181.5635\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 176.99460\n",
      "Epoch 13/50\n",
      "10152/10152 [==============================] - 1s 144us/step - loss: 183.5472 - mean_absolute_error: 183.5472 - val_loss: 173.3826 - val_mean_absolute_error: 173.3826\n",
      "\n",
      "Epoch 00013: val_loss improved from 176.99460 to 173.38258, saving model to Weights---173.38258.hdf5\n",
      "Epoch 14/50\n",
      "10152/10152 [==============================] - 1s 126us/step - loss: 181.6123 - mean_absolute_error: 181.6123 - val_loss: 187.3148 - val_mean_absolute_error: 187.3148\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 173.38258\n",
      "Epoch 15/50\n",
      "10152/10152 [==============================] - 1s 123us/step - loss: 186.4421 - mean_absolute_error: 186.4421 - val_loss: 175.3551 - val_mean_absolute_error: 175.3551\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 173.38258\n",
      "Epoch 16/50\n",
      "10152/10152 [==============================] - 1s 132us/step - loss: 181.5308 - mean_absolute_error: 181.5308 - val_loss: 180.8367 - val_mean_absolute_error: 180.8367\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 173.38258\n",
      "Epoch 17/50\n",
      "10152/10152 [==============================] - 1s 136us/step - loss: 179.4582 - mean_absolute_error: 179.4582 - val_loss: 242.4841 - val_mean_absolute_error: 242.4841\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 173.38258\n",
      "Epoch 18/50\n",
      "10152/10152 [==============================] - 1s 120us/step - loss: 184.5819 - mean_absolute_error: 184.5819 - val_loss: 178.4157 - val_mean_absolute_error: 178.4157\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 173.38258\n",
      "Epoch 19/50\n",
      "10152/10152 [==============================] - 1s 136us/step - loss: 177.7865 - mean_absolute_error: 177.7865 - val_loss: 183.1441 - val_mean_absolute_error: 183.1441\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 173.38258\n",
      "Epoch 20/50\n",
      "10152/10152 [==============================] - 1s 133us/step - loss: 175.9006 - mean_absolute_error: 175.9006 - val_loss: 175.1211 - val_mean_absolute_error: 175.1211\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 173.38258\n",
      "Epoch 21/50\n",
      "10152/10152 [==============================] - 1s 122us/step - loss: 177.4564 - mean_absolute_error: 177.4564 - val_loss: 185.7439 - val_mean_absolute_error: 185.7439\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 173.38258\n",
      "Epoch 22/50\n",
      "10152/10152 [==============================] - 1s 119us/step - loss: 176.0598 - mean_absolute_error: 176.0598 - val_loss: 220.0339 - val_mean_absolute_error: 220.0339\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 173.38258\n",
      "Epoch 23/50\n",
      "10152/10152 [==============================] - 1s 134us/step - loss: 178.1010 - mean_absolute_error: 178.1010 - val_loss: 181.2306 - val_mean_absolute_error: 181.2306\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 173.38258\n",
      "Epoch 24/50\n",
      "10152/10152 [==============================] - 1s 129us/step - loss: 178.3624 - mean_absolute_error: 178.3624 - val_loss: 172.5435 - val_mean_absolute_error: 172.5435\n",
      "\n",
      "Epoch 00024: val_loss improved from 173.38258 to 172.54354, saving model to Weights---172.54354.hdf5\n",
      "Epoch 25/50\n",
      "10152/10152 [==============================] - 1s 139us/step - loss: 176.1702 - mean_absolute_error: 176.1702 - val_loss: 183.0549 - val_mean_absolute_error: 183.0549\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 172.54354\n",
      "Epoch 26/50\n",
      "10152/10152 [==============================] - 1s 120us/step - loss: 177.6270 - mean_absolute_error: 177.6270 - val_loss: 192.6269 - val_mean_absolute_error: 192.6269\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 172.54354\n",
      "Epoch 27/50\n",
      "10152/10152 [==============================] - 1s 131us/step - loss: 181.5044 - mean_absolute_error: 181.5044 - val_loss: 202.9613 - val_mean_absolute_error: 202.9613\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 172.54354\n",
      "Epoch 28/50\n",
      "10152/10152 [==============================] - 1s 130us/step - loss: 175.3027 - mean_absolute_error: 175.3027 - val_loss: 187.5444 - val_mean_absolute_error: 187.5444\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 172.54354\n",
      "Epoch 29/50\n",
      "10152/10152 [==============================] - 1s 132us/step - loss: 174.1538 - mean_absolute_error: 174.1538 - val_loss: 186.4607 - val_mean_absolute_error: 186.4607\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 172.54354\n",
      "Epoch 30/50\n",
      "10152/10152 [==============================] - 1s 131us/step - loss: 174.2033 - mean_absolute_error: 174.2033 - val_loss: 177.0664 - val_mean_absolute_error: 177.0664\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 172.54354\n",
      "Epoch 31/50\n",
      "10152/10152 [==============================] - 1s 131us/step - loss: 175.9654 - mean_absolute_error: 175.9654 - val_loss: 174.1477 - val_mean_absolute_error: 174.1477\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 172.54354\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10152/10152 [==============================] - 1s 135us/step - loss: 174.4498 - mean_absolute_error: 174.4498 - val_loss: 173.9047 - val_mean_absolute_error: 173.9047\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 172.54354\n",
      "Epoch 33/50\n",
      "10152/10152 [==============================] - 1s 132us/step - loss: 171.8557 - mean_absolute_error: 171.8557 - val_loss: 173.3207 - val_mean_absolute_error: 173.3207\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 172.54354\n",
      "Epoch 34/50\n",
      "10152/10152 [==============================] - 1s 135us/step - loss: 170.4546 - mean_absolute_error: 170.4546 - val_loss: 179.8013 - val_mean_absolute_error: 179.8013\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 172.54354\n",
      "Epoch 35/50\n",
      "10152/10152 [==============================] - 2s 155us/step - loss: 177.4834 - mean_absolute_error: 177.4834 - val_loss: 187.0293 - val_mean_absolute_error: 187.0293\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 172.54354\n",
      "Epoch 36/50\n",
      "10152/10152 [==============================] - 1s 145us/step - loss: 170.9036 - mean_absolute_error: 170.9036 - val_loss: 174.4459 - val_mean_absolute_error: 174.4459\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 172.54354\n",
      "Epoch 37/50\n",
      "10152/10152 [==============================] - 1s 147us/step - loss: 172.2660 - mean_absolute_error: 172.2660 - val_loss: 173.5321 - val_mean_absolute_error: 173.5321\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 172.54354\n",
      "Epoch 38/50\n",
      "10152/10152 [==============================] - 1s 120us/step - loss: 169.1787 - mean_absolute_error: 169.1787 - val_loss: 181.3230 - val_mean_absolute_error: 181.3230\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 172.54354\n",
      "Epoch 39/50\n",
      "10152/10152 [==============================] - 1s 122us/step - loss: 169.4557 - mean_absolute_error: 169.4557 - val_loss: 200.2521 - val_mean_absolute_error: 200.2521\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 172.54354\n",
      "Epoch 40/50\n",
      "10152/10152 [==============================] - 1s 123us/step - loss: 169.7693 - mean_absolute_error: 169.7693 - val_loss: 177.4157 - val_mean_absolute_error: 177.4157\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 172.54354\n",
      "Epoch 41/50\n",
      "10152/10152 [==============================] - 1s 138us/step - loss: 171.7955 - mean_absolute_error: 171.7955 - val_loss: 171.5910 - val_mean_absolute_error: 171.5910\n",
      "\n",
      "Epoch 00041: val_loss improved from 172.54354 to 171.59095, saving model to Weights---171.59095.hdf5\n",
      "Epoch 42/50\n",
      "10152/10152 [==============================] - 1s 123us/step - loss: 168.9689 - mean_absolute_error: 168.9689 - val_loss: 203.6657 - val_mean_absolute_error: 203.6657\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 171.59095\n",
      "Epoch 43/50\n",
      "10152/10152 [==============================] - 1s 127us/step - loss: 168.4836 - mean_absolute_error: 168.4836 - val_loss: 175.2486 - val_mean_absolute_error: 175.2486\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 171.59095\n",
      "Epoch 44/50\n",
      "10152/10152 [==============================] - 1s 126us/step - loss: 169.7141 - mean_absolute_error: 169.7141 - val_loss: 175.4621 - val_mean_absolute_error: 175.4621\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 171.59095\n",
      "Epoch 45/50\n",
      "10152/10152 [==============================] - 1s 122us/step - loss: 165.3007 - mean_absolute_error: 165.3007 - val_loss: 186.3686 - val_mean_absolute_error: 186.3686\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 171.59095\n",
      "Epoch 46/50\n",
      "10152/10152 [==============================] - 1s 137us/step - loss: 169.4015 - mean_absolute_error: 169.4015 - val_loss: 214.2761 - val_mean_absolute_error: 214.2761\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 171.59095\n",
      "Epoch 47/50\n",
      "10152/10152 [==============================] - 2s 163us/step - loss: 166.9188 - mean_absolute_error: 166.9188 - val_loss: 194.2819 - val_mean_absolute_error: 194.2819\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 171.59095\n",
      "Epoch 48/50\n",
      "10152/10152 [==============================] - 1s 122us/step - loss: 166.1370 - mean_absolute_error: 166.1370 - val_loss: 171.3852 - val_mean_absolute_error: 171.3852\n",
      "\n",
      "Epoch 00048: val_loss improved from 171.59095 to 171.38520, saving model to Weights---171.38520.hdf5\n",
      "Epoch 49/50\n",
      "10152/10152 [==============================] - 1s 131us/step - loss: 165.1188 - mean_absolute_error: 165.1188 - val_loss: 172.5536 - val_mean_absolute_error: 172.5536\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 171.38520\n",
      "Epoch 50/50\n",
      "10152/10152 [==============================] - 1s 138us/step - loss: 166.9721 - mean_absolute_error: 166.9721 - val_loss: 182.5669 - val_mean_absolute_error: 182.5669\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 171.38520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24283843e48>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = X.shape[1], activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "# NN_model.add(Dropout(rate=0.8))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "# NN_model.summary()\n",
    "checkpoint_name = 'Weights---{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]\n",
    "NN_model.fit(X, Y, epochs=50, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wights file of the best model :\n",
    "wights_file = 'Weights---171.38520.hdf5' # choose the best checkpoint \n",
    "NN_model.load_weights(wights_file) # load it\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "# preds = NN_model.predict(X)\n",
    "# mae(preds,valY)\n",
    "# print_score(NN_model,False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
